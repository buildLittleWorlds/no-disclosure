<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Blog</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header id="top">
        <nav>
            <ul>
                <li><a href="index.html" class="active">Home</a></li>
                <li><a href="about.html">About</a></li>
            </ul>
        </nav>
        <h1>No Disclosure</h1>
        <p class="subtitle">a blog against AI transparency</p>
    </header>

    <div class="content-wrapper">
        <aside class="table-of-contents">
            <h2>Posts</h2>
            <nav class="post-navigation">
                <ul>
                    <li><a href="#top">Top</a></li>
                    <li><a href="#post-3">Who Gets to Decide...</a></li>
                    <li><a href="#post-2">Disclosure is a Dead End...</a></li>
                    <li><a href="#post-1">My Methods Are My Own...</a></li>
                </ul>
            </nav>
        </aside>

        <main>
            <article id="post-3" class="blog-post">
                <h2>Who Gets to Decide How We Create? The Politics Behind the Demand for AI Disclosure</h2>
                <div class="post-meta">
                    <time datetime="2025-01-31">January 31, 2025</time>
                </div>
                <p>We've established the principle: creators have a right to method privacy. And we've explored the practical and philosophical flaws in demanding AI disclosure. Now, let's delve into the deeper, perhaps less comfortable, truth: the demand for disclosure isn't really about ethics, transparency, or even quality. It's about control. It's about power dynamics, and ultimately, it's driven by fear.</p>

                <p>Think about the current wave of publisher guidelines prohibiting or requiring disclosure of AI use. On the surface, they often present themselves as ethically motivated, concerned about "authenticity" or "human creativity." And for some, these concerns may be genuine. But peel back the layers, and you'll find something else at play: a deep-seated fear of change, and a desire to maintain existing power structures in the creative industries.</p>

                <p>The rapid rise of AI content generation is undeniably disruptive. It challenges established notions of authorship, threatens traditional workflows, and potentially shifts the balance of power between creators, publishers, and audiences. The demand for disclosure, in this context, becomes a defensive maneuver. It's a way to slow down the adoption of AI, to create friction, to make it harder for AI-assisted creators to compete with those who adhere to more traditional methods. It's a form of gatekeeping, disguised as ethical concern.</p>

                <p>Consider the hypocrisy inherent in many of these guidelines. Are we really to believe that publishers themselves are not exploring and implementing AI tools to assist in their own work – in editing, marketing, even content generation for internal purposes? Of course not. Publishing, like any industry, is constantly seeking efficiencies and leveraging new technologies. The prohibition on AI use often seems to be selectively applied – to creators, not to the publishing process itself. This double standard reveals the true motivation: not a principled stance against AI in all forms, but a desire to control how and by whom AI is used in the creative ecosystem.</p>

                <p>These anti-AI guidelines, framed as protecting "human creativity," can inadvertently become tools for restricting creative freedom. They empower publishers to dictate not just the what of creative work (the final product), but also the how (the methods used to create it). As I argued in the first post, this is a dangerous overreach. It cedes even more power to publishers, who already hold significant sway over creators' livelihoods and visibility. For creators, especially those who might see AI as an empowering tool, these guidelines can feel like a form of censorship, a limitation on their artistic agency.</p>

                <p>The underlying fear driving this push for disclosure is, I believe, a fear of the unknown. It's a fear of a creative landscape where AI plays a more prominent role, where the lines between human and machine creativity become increasingly blurred. It's a fear that AI will devalue "human" creativity, or displace human creators altogether. And while these are valid anxieties to explore, framing the solution as mandatory disclosure is ultimately a reactive, and ultimately ineffective, approach. It's trying to hold back the tide of technological change by focusing on the tools rather than engaging with the evolving nature of creation itself.</p>

                <p>Instead of policing methods and clinging to outdated definitions of authorship, we need to have a more nuanced and forward-looking conversation. We need to shift our focus from how something is made to the value of what is made. Is the work compelling? Is it original? Does it resonate with audiences? These are the questions that should matter, regardless of the tools or methods employed in its creation.</p>

                <p>My radical position – the right to method privacy – is not about ignoring the ethical considerations of AI. It's about reframing the debate. It's about resisting the urge to control and restrict, and instead embracing a more open and evolving understanding of authorship in the age of AI. It's about empowering creators to explore new tools and methods without fear of judgment or censorship. And ultimately, it's about recognizing that the true measure of creative work lies not in the secret of its making, but in the impact it has on the world.</p>

                <p>This is just the beginning of this conversation. I invite you to push back, to challenge my position, to help us all develop a more robust and nuanced understanding of authorship in this rapidly changing landscape. What do you think? Who should get to decide how we create?</p>
            </article>

            <article id="post-2" class="blog-post">
                <h2>Disclosure is a Dead End: Why the AI Method Debate Misses the Realities of Creation</h2>
                <div class="post-meta">
                    <time datetime="2025-01-30">January 30, 2025</time>
                </div>
                <p>In my previous post, I argued for a principled stance: creators have a right to keep their methods private. This isn't just a matter of personal preference; it's about recognizing the inherent value of the creative process itself and defending the autonomy of the artist.</p>

                <p>But beyond the principle, there are crucial practical and philosophical reasons why the current focus on AI disclosure is not only misguided but ultimately a dead end. It's a debate that's heading in the wrong direction, chasing a chimera while ignoring the deeper shifts happening in the nature of creation itself.</p>

                <p>Let's start with the practical. Right now, asking "Did you use AI?" might seem like a reasonable, if intrusive, question. But we are rapidly moving towards a world where AI is not a separate tool, but an integrated element of our creative environments. Imagine workplaces, software, even personal devices where AI assistance is woven into every step of the process, from brainstorming to sentence structuring, from visual ideation to musical arrangement.</p>

                <p>In such a world, how do you even define "using AI"? Where does the human input begin and the AI assistance end? Will we demand creators dissect every micro-interaction with AI, tracing back every suggestion, every auto-correction, every spark of inspiration that might have been subtly nudged by an algorithm? It's not just impractical; it's verging on the absurd. The lines are blurring, and soon they'll be indistinguishable. Disclosure will become an impossible, and ultimately meaningless, exercise.</p>

                <p>And this leads us to a more fundamental, philosophical point: the demand for disclosure often rests on a flawed premise – the myth of the isolated, individual creative mind. It assumes that authorship springs solely from a singular, bounded consciousness, untouched by external influences unless explicitly declared. But this is a romanticized, and ultimately inaccurate, picture of how creativity actually works.</p>

                <p>None of us create in a vacuum. Our language, our ideas, our very ways of thinking are shaped by a vast, collective inheritance. We are all, in a sense, drawing from a common well of human experience and expression. We didn't invent the words we use, the artistic traditions we build upon, or the cultural narratives that inform our work. Creativity is always, to some degree, a process of curation – of selecting, arranging, and reinterpreting elements from the world around us.</p>

                <p>And in this light, AI becomes simply another, albeit powerful, tool for curation. It's a way to engage with and focus this vast collective knowledge base, to experiment with patterns and possibilities on a scale previously unimaginable. To demand disclosure of AI use is to cling to an outdated notion of individual genius, ignoring the fundamentally collaborative and curated nature of all creative work.</p>

                <p>This isn't just abstract theory. In a recent video clip (which I encourage you to watch, starting at 40:22 in <a href="https://www.youtube.com/watch?v=i4GIuFlDwiY" target="_blank">this discussion</a>), Simon Willison, along with other tech-savvy creators, grapples with exactly these questions. They discuss how authorship is being redefined in real-time, acknowledging that it's not about rigid definitions but about an ongoing negotiation of what we value and recognize as meaningful creative contribution. This conversation, happening amongst those actively building the future of the web and AI, highlights that the narrow focus on "AI disclosure" is missing the much larger, more complex, and frankly more interesting conversation about the evolving nature of authorship itself.</p>

                <p>Instead of getting bogged down in the impracticality of policing AI use and clinging to outdated notions of individual creation, we need to shift our focus. We need to ask more nuanced questions about what constitutes valuable creative work in this new landscape. We need to move beyond the binary of "AI-generated" versus "human-made" and start engaging with the actual qualities of the work itself, regardless of the methods used to create it. Because ultimately, the real value lies not in the how, but in the what – in the impact, the originality, and the meaning of the creative output.</p>
            </article>

            <article id="post-1" class="blog-post">
                <h2>My Methods Are My Own: Why Creators Have a Right to Privacy in the AI Age</h2>
                <div class="post-meta">
                    <time datetime="2025-01-29">January 29, 2025</time>
                </div>
                <p>We're in a moment of profound shift for authorship. AI content generation is forcing us to confront fundamental questions about what it means to create, to write, to be an artist. Publishers are scrambling to create guidelines, often demanding disclosure about AI use, or outright banning it. Many creators, understandably, feel threatened and want to draw a line in the sand.</p>

                <p>But I want to propose a different line. A line drawn not in fear, but in principle. A line that, while perhaps radical, is rooted in the very foundations of artistic ownership and creative freedom.</p>

                <p>My position is this: creators have an inherent right to keep their methods of composition private.</p>

                <p>It's a simple statement, but it carries significant weight. It means that when a publisher asks, "Did you use AI in this?" the only truly principled answer is, "That's none of your business."</p>

                <p>Why take such a seemingly confrontational stance? Because the methods of artistic production are as much a part of the creator's intellectual property as the finished work itself. Think about it: for centuries, artists, writers, and craftspeople have guarded their techniques, their secrets, their unique approaches. These methods are not just incidental to the creation process; they are the creation process, the very engine of artistic output.</p>

                <p>Imagine a chef being forced to disclose every ingredient ratio, every cooking technique, every source of inspiration before anyone could taste their dish. Recipes, after all, are considered intellectual property. Why should artistic methods be any different? Just as the chef's recipe is their carefully developed and guarded asset, so too are the writer's unique blend of research, drafting processes, and yes, even tools – AI or otherwise.</p>

                <p>The relationship between artist and audience, between writer and reader, is fundamentally built on a kind of tacit agreement. The artist creates a world, an experience, an illusion – and if it resonates, if it moves the audience, then the artist has fulfilled their part of the bargain. The audience is free to judge the result: is it compelling? Is it original? Is it meaningful? But the how – the specific steps, the tools, the internal processes – that should remain firmly within the creator's domain.</p>

                <p>When publishers demand disclosure of AI use, they are stepping outside their lane. Their role is to evaluate the quality and suitability of the work for their publication. To dictate the methods of creation is to fundamentally shift the power dynamic, tilting it even further away from the creator and towards the already powerful publishing apparatus. Writers and artists, often eager for recognition and publication, already cede significant rights. But the right to control one's own creative process, to maintain the privacy of one's methods – this is a line we cannot afford to cross.</p>

                <p>This isn't just about AI. It's about artistic autonomy. It's about respecting the hidden craft that has always been at the heart of creation. It's about recognizing that the methods, the secrets, the how of art are just as valuable, and just as rightfully owned by the creator, as the art itself. It's time to reclaim that ownership, to assert that our methods are, and should remain, our own business.</p>
            </article>
        </main>
    </div>

    <footer>
        <p>&copy; 2025 My Blog. All rights reserved.</p>
    </footer>
</body>
</html>