<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Blog</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header id="top">
        <nav>
            <ul>
                <li><a href="index.html" class="active">Home</a></li>
                <li><a href="about.html">About</a></li>
            </ul>
        </nav>
        <h1>No Disclosure</h1>
        <p class="subtitle">a blog against AI transparency</p>
    </header>

    <div class="content-wrapper">
        <aside class="table-of-contents">
            <h2>Posts</h2>
            <nav class="post-navigation">
                <ul>
                    <li><a href="#top">Top</a></li>
                    <li><a href="#post-5">Against Art Surveillance</a></li>
                    <li><a href="#post-4">U.S. Copyright Office Update</a></li>
                    <li><a href="#post-3">Song and Dance Man</a></li>
                    <li><a href="#post-2">Who Decides How a Writer Writes?</a></li>
                    <li><a href="#post-1">No Disclosure</a></li>
                </ul>
            </nav>
        </aside>

        <main>
            <article id="post-5" class="blog-post">
                <h2>Against Art Surveillance</h2>
                <div class="post-meta">
                    <time datetime="2025-01-31">January 31, 2025</time>
                </div>
                <p>The claim is simple: artists should not be forced to reveal their creative processes. Whether it's a magician refusing to divulge their secrets or a writer declining to explain every metaphor, the magic of art often resides in its mystery. However, a new demand threatens to erode this artistic autonomy: the call for mandatory transparency regarding the use of Artificial Intelligence in creative works.</p>

                <p>This demand feels chillingly familiar. In the aftermath of the horrific attacks of September 11th, 2001, fear gripped America. In the name of security, fundamental freedoms were traded for the promise of safety. We tolerated unprecedented levels of government surveillance, accepting the erosion of privacy as the price of protection against an unseen enemy. "Scary terrorist" became the justification for a vast expansion of the surveillance state.</p>

                <p>Now, in the burgeoning era of Artificial Intelligence, we see a similar dynamic emerging, albeit in the realm of art. Swap out "scary terrorist" for "scary AI," and the architecture of fear and control snaps into place. Driven by a potent cocktail of ignorance and apprehension, institutions and voices are rising to demand "transparency" in art creation. The recent U.S. Copyright Office report, <a href="https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-2-Copyrightability-Report.pdf">Copyright and Artificial Intelligence, Part 2: Copyrightability</a> (2025), inadvertently lays bare the mechanisms of this nascent "artistic surveillance."</p>

                <p>The report itself acknowledges the unsettling nature of this new technology: "The capabilities of the latest generative AI technologies raise challenging questions about the nature and scope of human authorship" (U.S. Copyright Office, 2025, p. 9). This framing immediately positions AI as a problem, a source of "challenging questions" that require interrogation. Just as the post-9/11 era was defined by a need to understand and control an unknown threat, so too is AI presented as a force demanding scrutiny.</p>

                <p>Furthermore, the report highlights the very "black box" nature of AI, inadvertently justifying the intrusive gaze it necessitates. "Some observers describe AI as a 'black box,' and even expert researchers are limited in their ability to understand or predict the behavior of specific models" (U.S. Copyright Office, 2025, p. 14). This echoes the perceived unknowability of the terrorist threat. If AI is a "black box," then, the logic goes, we must delve into the artist's process to ensure no uncopyrightable "AI art" slips through the cracks. This lack of understanding, this fear of the unknown, becomes the very justification for artistic surveillance.</p>

                <p>The document clarifies that determining copyright for AI-assisted works will not be a simple matter: "Whether human contributions to AI-generated outputs are sufficient to constitute authorship must be analyzed on a case-by-case basis" (U.S. Copyright Office, 2025, p. 8). This "case-by-case basis" isn't a neutral declaration; it's an operational directive for artistic surveillance. Imagine the implications: each artwork potentially subjected to an inquisition, artists compelled to meticulously document their process, to prove the "human contribution" is sufficient. This is not simply about defining copyright; it's about creating a system where artists are under constant suspicion, forced to open their studios and minds to institutional scrutiny.</p>

                <p>Just as the surveillance state after 9/11 built digital dossiers on citizens, artistic surveillance will demand digital dossiers on creative processes. If an artist is denied copyright based on the suspicion of AI involvement, what recourse do they have? The report implicitly answers: they must disclose. They must make public the very methods and techniques that define their artistic voice, potentially diminishing its mystique and undermining their livelihood. This is the insidious trade: artistic freedom for the illusion of copyright purity, mirroring the earlier trade of civil liberties for the illusion of absolute security.</p>

                <p>We were promised safety in exchange for freedom after 9/11, but we learned that security at the cost of liberty is a hollow promise. Similarly, the promise of "protecting human authorship" through artistic surveillance will only stifle creativity and erode artistic autonomy. Just as we should have resisted the knee-jerk expansion of surveillance after 9/11, artists and art lovers must resist this creeping demand for AI transparency. "No Disclosure" is not just about artistic mystery; it's now about resisting artistic surveillance and defending the fundamental freedom to create without the shadow of suspicion and the demand for constant, process-revealing transparency.</p>

                <div class="reference">
                    <p><strong>Reference</strong></p>
                    <p>U.S. Copyright Office. (2025, January). <em>Copyright and artificial intelligence: Part 2: Copyrightability</em> (Report). Washington, DC: Author.</p>
                </div>
            </article>

            <article id="post-4" class="blog-post">
                <h2>U.S. Copyright Office Update</h2>
                <div class="post-meta">
                    <time datetime="2025-01-31">January 31, 2025</time>
                </div>
                <p>On January 29, 2025 the U.S. Copyright Office released <a href="https://www.copyright.gov/ai/Copyright-and-Artificial-Intelligence-Part-2-Copyrightability-Report.pdf">Part 2</a> of its updated guidance on copyright law in the context of changes in AI.</p>
                <p>In general, the update signals more copyright protection for creators using AI in their process. On the question of transparency and disclosure, however, the update is a bit of a mess. It implies in some places and states outright in others that a creator will be obligated to demonstrate in fine detail which parts of their work were original to them and which came from an AI. This is already totally impractical and will become less and less practical every day.</p>
            </article>

            <article id="post-3" class="blog-post">
                <h2>Song and Dance Man</h2>
                <div class="post-meta">
                    <time datetime="2025-01-31">January 31, 2025</time>
                </div>
                <p>The title comes from a <a href="https://www.youtube.com/shorts/rXCK7TJ9_bM">Bob Dylan press conference in 1965</a>. Dylan was getting pressured at the time to say whether he was a more a singer or a poet. His answer ("I think of myself more as a song and dance man, you know") was his way to say, "That goes to craft and method, and I'll keep those to myself."</p>
                <p>There's always been this push from the outside to force writers, magicians, circus performers, and tricksters to reveal how they do what they do. It's a natural curiosity, but the hidden source of the writer's work should stay hidden.</p>
                <p>A large part of what a writer owns if a writer owns anything at all is the secret of how this particular writer makes a world that's totally made-up feel like maybe it's more real than anything else. That's magic. And a magician never tells.</p>
            </article>

            <article id="post-2" class="blog-post">
                <h2>Who Decides How a Writer Writes?</h2>
                <div class="post-meta">
                    <time datetime="2025-01-30">January 30, 2025</time>
                </div>
                <p>Here's what I think about publisher guidelines that prohibit the use of AI. If you're a creator who doesn't like AI and you see these anti-AI guidelines as "being on the right side" in the fight against AI, these guidelines might feel like they rise to the level of righteous activism. But I disagree.</p>
                <p>Who should determine the methods an artist uses for the creation of the artist's work?</p>
                <p>Who should determine the methods a publisher uses for the publishing of the artist's work?</p>
                <p>I say the publisher should be free to use the methods the publisher wants to use for the publishing of material the publisher has agreed to publish. This is what publishers do. Publishers take work submitted to them, determine the quality, select work they want to publish, and then use their technical expertise to put that work out into the world for readers.</p>
                <p>And I say artists should determine their own methods for creating the work they want to create. What is the appropriate response when a publisher asks, "Did you use AI to write this?"</p>
                <p>"That's none of your business. You stay in your lane, and I'll stay in mine."</p>
                <p>If artists give up the right to decide their own methods for the creation of their work, they hand over power to publishers. Publishers already have an out-sized power over the work of artists and writers. Writers are generally so grateful to get the attention of publishers that they sign over most rights to the publisher. But writers should have more respect for themselves as the owners of their own work, including the methods they use to create their work.</p>
            </article>

            <article id="post-1" class="blog-post">
                <h2>No Disclosure</h2>
                <div class="post-meta">
                    <time datetime="2025-01-29">January 29, 2025</time>
                </div>
                <p>My position is simple. I am against the requirement that creators disclose whether they use AI or not in their work. Writers decide what they want to write about; what they want to say about what they write about; and the methods they will use in writing what they write. These all belong to the writer, and the writer is under no obligation to reveal the methods of his craft.</p>
                <p>This blog is my attempt to work out the implications of this position.</p>
            </article>
        </main>
    </div>

    <footer>
        <p>&copy; 2025 Daniel Plate. All rights reserved.</p>
    </footer>
</body>
</html>